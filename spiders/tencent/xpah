
开始开始做个redis 的项目

scrapy startproject tencenls

#创建爬虫

scrapy genspider -t crawl tc "hr.tencent.com"


#非分布是，启动爬虫
scrapy crawl tencent





#分布式 执行命令
执行的命令为：
scrapy runspider tc.py
#redis  执行的命令为：
lpush tcspider:start_urls http://hr.tencent.com/position.php?&start=0






url = response.url

start_url = ["http://d.wz.sun0769.com/index.php/department?page="]
#http://d.wz.sun0769.com/index.php/department?page=20

LinkExtractor(allow =r'?page=\d+',follow = Ture)

#http://wz.sun0769.com/html/question/201806/376845.shtml

LinkExtractor(allow =r'/question/\d+/\d+.shtml',callback = "parsedongguan")


def parsedongguan(self,response):
    item = dongguanItem()

    #标题
    item["title"] = response.xpath('//div[@class="pagecenter p3"]//strong//text()').extract()[0]
    #编号
    item["num"] = title.split('.')[-1].split(":")[-1]
    #内容
    item["content"] = response.xpath('//div[@class="c1 text14_2"]/text()').extract()[0]
    #链接
    item["url"] = response.url

    yield item





urls =


title = response.xpath('//div[@class="pagecenter p3"]//strong//text()').extract()[0]
num = title.split('.')[-1].split(":")[-1]

content =  response.xpath('//div[@class="c1 text14_2"]/text()').extract()[0]





